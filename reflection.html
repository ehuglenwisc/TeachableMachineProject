<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Reflection - Teachable Machine</title>
  <link rel="stylesheet" href="styles.css">
</head>
<body>

<nav>
  <a href="index.html">Home</a>
  <a href="reflection.html">Reflection</a>
  <a href="ml.html">Machine Learning</a>
  <a href="references.html">References</a>
</nav>

<h1>Reflection on "Unmasking AI"</h1>
<div class="reflection-text">

  <section id="reflection">
    <h2>Reflection</h2>

    <h3>Introducing Our Algorithm</h3>
    <p>
      Our algorithm is designed to recognize common objects such as pencils, notebooks, glasses, and water bottles. When the algorithm gets close to correctly identifying an object, it audibly announces the name of the object. This feature is particularly aimed at assisting individuals with visual impairments, making it a tool with both educational and practical value. As we develop this project, the insights from Buolamwini’s <em>Unmasking AI</em> resonate strongly with us, inspiring us to prioritize equity, representation, and ethical considerations in our design.
    </p>

    <h3>Accessibility</h3>
    <p>
      The decision to focus on everyday objects stems from a desire to create an algorithm that is both approachable and impactful. These items are universal, easily accessible, and frequently encountered, making the algorithm applicable in various settings. By integrating a voice feature, we aim to bridge a critical gap in accessibility for individuals who are blind or visually impaired. This aligns with our broader commitment to designing technology that serves diverse user needs, rather than perpetuating exclusionary practices.
    </p>

    <h3>Ethical Considerations</h3>
    <p>
      Buolamwini’s work sheds light on the systemic disparities in AI systems, from biased datasets to exclusionary design processes. These lessons are central to our project. As we train our algorithm, we ensure that our dataset includes variations in lighting, angles, and object appearances to improve its accuracy across different contexts. This effort reflects Buolamwini’s emphasis on diverse and representative data, a principle we take seriously to ensure our algorithm performs reliably for all users.
    </p>
    <p>
      One of the most striking lessons from <em>Unmasking AI</em> is the idea that bias is not an inevitable flaw in AI but rather a result of choices made during its development. This insight challenges us to be intentional in every aspect of our design, from how we label objects to testing for inaccuracies that could disproportionately affect individuals with disabilities.
    </p>

    <h3>Universal Design</h3>
    <p>
      The voice feature of our algorithm is inspired by the principle of universal design—the idea that technology should be accessible and usable by everyone, regardless of ability. This feature allows the algorithm to communicate directly with users, providing immediate feedback and making the tool more intuitive. By anticipating challenges such as ambient noise and voice variation, we strive to create a robust and user-friendly tool adaptable to diverse environments.
    </p>
    <p>
      Buolamwini’s critique of the lack of accountability in AI development motivates us to document every design decision transparently. This practice not only aligns with her call for accountability but also serves as a model for ethical AI development.
    </p>

    <h3>Teachable Machines</h3>
    <p>
      Working with Teachable Machines has allowed us to engage directly with some of the challenges Buolamwini describes. The platform’s simplicity enables us to experiment with datasets and refine our algorithm iteratively. This hands-on approach has deepened our understanding of how biases emerge and the strategies to mitigate them, reinforcing the importance of continuous testing and improvement.
    </p>

    <h3>Unmasking AI</h3>
    <p>
      Reflecting on <em>Unmasking AI</em>, we are reminded of AI’s dual potential. On one hand, AI can empower and assist, as demonstrated by our algorithm’s ability to vocalize object names for users with visual impairments. On the other hand, AI can marginalize and harm when developed carelessly. This duality underscores the importance of pairing innovation with responsibility.
    </p>
    <p>
      Buolamwini’s vision of “justice-oriented AI” inspires us to prioritize equity, accountability, and human dignity in our work. By making our algorithm adaptable to diverse contexts and needs, we aim to demonstrate how AI can be inclusive and impactful.
    </p>

    <h3>Representation and Collaboration</h3>
    <p>
      The development of our algorithm reflects the importance of representation in AI. Buolamwini argues that the people designing these systems shape their values and impacts. This insight reminds us to consider our own identities and experiences as we approach this project. At the same time, we recognize the need for broader representation in AI development and are inspired by Buolamwini’s advocacy for diversity and justice in tech. Through this project, we aim to contribute to a more inclusive vision of AI, where diverse perspectives inform both the design and application of technology.
    </p>
    <p>
      As we complete this assignment, we are reminded of the power of collective action. Buolamwini’s advocacy has sparked a global movement for algorithmic justice, showing that change is possible when people come together to demand accountability. Similarly, our group project is a testament to the potential of collaboration. By pooling our skills and perspectives, we are able to tackle complex challenges and learn from one another. This spirit of collaboration is central to our approach, and we hope it inspires others to join the effort to create more equitable AI systems.
    </p>
  </section>


</div>

</body>
</html>

