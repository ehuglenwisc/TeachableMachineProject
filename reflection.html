<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Reflection - Teachable Machine</title>
  <link rel="stylesheet" href="styles.css">
</head>
<body>

<nav>
  <a href="index.html">Home</a>
  <a href="ml.html">Machine Learning</a>
  <a href="references.html">References</a>
</nav>

<h1>Reflection on "Unmasking AI"</h1>

<p>
  Our algorithm is designed to recognize common objects such as pencils, notebooks, glasses, and water bottles. When the algorithm gets close to correctly identifying an object, it will audibly announce the name of the object. This feature is particularly aimed at assisting individuals with visual impairments, making it a tool with both educational and practical value. As we develop this project, the insights from Buolamwini’s *Unmasking AI* resonate strongly with us, inspiring us to prioritize equity, representation, and ethical considerations in our design.
</p>

<p>
  The decision to focus on everyday objects stems from a desire to create an algorithm that is both approachable and impactful. These items are universal, easily accessible, and frequently encountered, making the algorithm applicable in various settings. By integrating a voice feature, we aim to bridge a critical gap in accessibility for individuals who are blind or visually impaired. This aligns with our broader commitment to designing technology that serves diverse user needs, rather than perpetuating exclusionary practices.
</p>

<p>
  Buolamwini’s work sheds light on the systemic disparities in AI systems, from biased datasets to exclusionary design processes. These lessons are central to our project. For example, as we train our algorithm, we ensure that our dataset includes variations in lighting, angles, and object appearances to improve its accuracy across different contexts. This effort reflects Buolamwini’s emphasis on the importance of diverse and representative data, a principle we take seriously to ensure our algorithm performs reliably for all users.
</p>

<p>
  One of the most striking lessons from *Unmasking AI* is the idea that bias is not an inevitable flaw in AI but rather a result of choices made during its development. This insight challenges us to be intentional in every aspect of our design. For instance, we are careful about how we label and categorize objects, avoiding assumptions that might limit the algorithm’s effectiveness for certain users. Additionally, we test the algorithm extensively to identify and address any inaccuracies, particularly those that could disproportionately affect individuals with disabilities.
</p>

<p>
  The voice feature of our algorithm is inspired by the principle of universal design—the idea that technology should be accessible and usable by everyone, regardless of ability. This feature allows the algorithm to communicate directly with users, providing immediate feedback and making the tool more intuitive. In designing this functionality, we are mindful of the potential limitations of voice recognition systems, such as variations in pronunciation or ambient noise. By anticipating these challenges, we aim to create a robust and user-friendly tool that can adapt to diverse environments.
</p>

<p>
  Buolamwini’s critique of the lack of accountability in AI development also resonates with us. She highlights how profit-driven motives often overshadow considerations of fairness or justice, leading to technologies that exacerbate existing inequalities. This critique motivates us to approach our project with a strong sense of responsibility. We document our decisions and rationale at each step, creating a transparent record of our design process. This practice not only aligns with Buolamwini’s call for accountability but also serves as a model for others interested in ethical AI development.
</p>

<p>
  Another key theme from *Unmasking AI* is the disparity in access to AI tools and education. While platforms like Teachable Machines are designed to democratize AI, many communities still face barriers to participation. These include limited access to technology, a lack of technical training, and systemic exclusion from tech spaces. Our project seeks to challenge these barriers by making AI concepts approachable and demonstrating their relevance to real-world challenges. By sharing our process and emphasizing the accessibility of the tools we use, we hope to inspire others—particularly those from underrepresented backgrounds—to explore AI and see its potential for social impact.
</p>

<p>
  The development of our algorithm also reflects on the importance of representation in AI. Buolamwini argues that the people designing these systems shape their values and impacts. This insight reminds us to consider our own identities and experiences as we approach this project. At the same time, we recognize the need for broader representation in AI development and are inspired by Buolamwini’s advocacy for diversity and justice in tech. Through this project, we aim to contribute to a more inclusive vision of AI, where diverse perspectives inform both the design and application of technology.
</p>

<p>
  In practical terms, working with Teachable Machines allows us to engage directly with some of the challenges Buolamwini describes. For example, the platform’s simplicity enables us to experiment with different datasets and evaluate their effects on our algorithm’s performance. This hands-on experience deepens our understanding of how biases can emerge and how they might be mitigated. It also reinforces the importance of iterative testing and refinement, as even well-intentioned designs can produce unintended consequences.
</p>

<p>
  As we reflect on the lessons from *Unmasking AI*, we are reminded of the dual nature of AI’s potential. On one hand, AI can empower and assist individuals in meaningful ways, as demonstrated by our algorithm’s ability to vocalize object names for users with visual impairments. On the other hand, AI can marginalize and harm if developed carelessly, as seen in many of the examples Buolamwini discusses. This duality underscores the importance of approaching AI with both innovation and responsibility.
</p>

<p>
  One of the most empowering aspects of this project is the opportunity to reimagine what AI can be. Rather than accepting the status quo, we are inspired by Buolamwini’s vision of “justice-oriented AI”—a paradigm that prioritizes equity, accountability, and human dignity. This vision guides our approach, encouraging us to think beyond technical performance and consider the social impact of our algorithm. For example, we explore ways to make our algorithm adaptable to different contexts, ensuring it remains useful and inclusive for a wide range of users.
</p>

<p>
  Through this journey, we have come to appreciate the interconnectedness of technical and ethical considerations in AI. Buolamwini’s work underscores the idea that technology is never neutral—it reflects the values and priorities of its creators. This insight challenges us to be intentional about the values we embed in our algorithm and to remain vigilant against the biases that can arise. It also reminds us that small-scale projects like ours can contribute to broader conversations about ethical AI, demonstrating that fairness and inclusivity are achievable goals.
</p>

<p>
  As we complete this assignment, we are reminded of the power of collective action. Buolamwini’s advocacy has sparked a global movement for algorithmic justice, showing that change is possible when people come together to demand accountability. Similarly, our group project is a testament to the potential of collaboration. By pooling our skills and perspectives, we are able to tackle complex challenges and learn from one another. This spirit of collaboration is central to our approach, and we hope it inspires others to join the effort to create more equitable AI systems.
</p>

<p>
  In conclusion, this project has been an eye-opening experience for us, both technically and ethically. *Unmasking AI* has challenged us to think critically about the disparities in AI and to take responsibility for the choices we make as creators. It has also inspired us to envision a more inclusive future for AI, where technology serves the needs of all communities rather than reinforcing existing inequalities. By designing an algorithm that recognizes everyday objects and vocalizes their names, we aim to contribute to this vision, demonstrating how AI can be both innovative and equitable.
</p>

</body>
</html>

